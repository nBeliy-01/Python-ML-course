{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUPArbcFJKzJ"
   },
   "source": [
    "У цьому ДЗ ми потренуємось розв'язувати задачу багатокласової класифікації за допомогою логістичної регресії з використанням стратегій One-vs-Rest та One-vs-One, оцінити якість моделей та порівняти стратегії."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f4tzX6YomVv"
   },
   "source": [
    "### Опис задачі і даних\n",
    "\n",
    "**Контекст**\n",
    "\n",
    "В цьому ДЗ ми працюємо з даними про сегментацію клієнтів.\n",
    "\n",
    "Сегментація клієнтів – це практика поділу бази клієнтів на групи індивідів, які схожі між собою за певними критеріями, що мають значення для маркетингу, такими як вік, стать, інтереси та звички у витратах.\n",
    "\n",
    "Компанії, які використовують сегментацію клієнтів, виходять з того, що кожен клієнт є унікальним і що їхні маркетингові зусилля будуть більш ефективними, якщо вони орієнтуватимуться на конкретні, менші групи зі зверненнями, які ці споживачі вважатимуть доречними та які спонукатимуть їх до купівлі. Компанії також сподіваються отримати глибше розуміння уподобань та потреб своїх клієнтів з метою виявлення того, що кожен сегмент цінує найбільше, щоб точніше адаптувати маркетингові матеріали до цього сегменту.\n",
    "\n",
    "**Зміст**.\n",
    "\n",
    "Автомобільна компанія планує вийти на нові ринки зі своїми існуючими продуктами (P1, P2, P3, P4 і P5). Після інтенсивного маркетингового дослідження вони дійшли висновку, що поведінка нового ринку схожа на їхній існуючий ринок.\n",
    "\n",
    "На своєму існуючому ринку команда з продажу класифікувала всіх клієнтів на 4 сегменти (A, B, C, D). Потім вони здійснювали сегментовані звернення та комунікацію з різними сегментами клієнтів. Ця стратегія працювала для них надзвичайно добре. Вони планують використати ту саму стратегію на нових ринках і визначили 2627 нових потенційних клієнтів.\n",
    "\n",
    "Ви маєте допомогти менеджеру передбачити правильну групу для нових клієнтів.\n",
    "\n",
    "В цьому ДЗ використовуємо дані `customer_segmentation_train.csv`[скачати дані](https://drive.google.com/file/d/1VU1y2EwaHkVfr5RZ1U4MPWjeflAusK3w/view?usp=sharing). Це `train.csv`з цього [змагання](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZFXPKx1JX-3"
   },
   "source": [
    "**Завдання 1.** Завантажте та підготуйте датасет до аналізу. Виконайте обробку пропущених значень та необхідне кодування категоріальних ознак. Розбийте на тренувальну і тестувальну вибірку, де в тесті 20%. Памʼятаємо, що весь препроцесинг ліпше все ж тренувати на тренувальній вибірці і на тестувальній лише використовувати вже натреновані трансформери.\n",
    "Але в даному випадку оскільки значень в категоріях небагато, можна зробити обробку і на оригінальних даних, а потім розбити - це простіше. Можна також реалізувати процесинг і тренування моделі з пайплайнами. Обирайте як вам зручніше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "I-mwGqPS5GAT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('customer_segmentation_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8068.000000</td>\n",
       "      <td>8068.000000</td>\n",
       "      <td>7239.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>463479.214551</td>\n",
       "      <td>43.466906</td>\n",
       "      <td>2.641663</td>\n",
       "      <td>2.850123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2595.381232</td>\n",
       "      <td>16.711696</td>\n",
       "      <td>3.406763</td>\n",
       "      <td>1.531413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>458982.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>461240.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>463472.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>465744.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>467974.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID          Age  Work_Experience  Family_Size\n",
       "count    8068.000000  8068.000000      7239.000000  7733.000000\n",
       "mean   463479.214551    43.466906         2.641663     2.850123\n",
       "std      2595.381232    16.711696         3.406763     1.531413\n",
       "min    458982.000000    18.000000         0.000000     1.000000\n",
       "25%    461240.750000    30.000000         0.000000     2.000000\n",
       "50%    463472.500000    40.000000         1.000000     3.000000\n",
       "75%    465744.250000    53.000000         4.000000     4.000000\n",
       "max    467974.000000    89.000000        14.000000     9.000000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   int64\n",
       "Gender              object\n",
       "Ever_Married        object\n",
       "Age                  int64\n",
       "Graduated           object\n",
       "Profession          object\n",
       "Work_Experience    float64\n",
       "Spending_Score      object\n",
       "Family_Size        float64\n",
       "Var_1               object\n",
       "Segmentation        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                   0\n",
      "Gender               0\n",
      "Ever_Married       140\n",
      "Age                  0\n",
      "Graduated           78\n",
      "Profession         124\n",
      "Work_Experience    829\n",
      "Spending_Score       0\n",
      "Family_Size        335\n",
      "Var_1               76\n",
      "Segmentation         0\n",
      "dtype: int64 \n",
      "\n",
      "ID                  0.00\n",
      "Gender              0.00\n",
      "Ever_Married        1.74\n",
      "Age                 0.00\n",
      "Graduated           0.97\n",
      "Profession          1.54\n",
      "Work_Experience    10.28\n",
      "Spending_Score      0.00\n",
      "Family_Size         4.15\n",
      "Var_1               0.94\n",
      "Segmentation        0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum(), '\\n')\n",
    "print(np.round(100 * df.isnull().sum() / df.shape[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущених значень в змінних `Var_1` та `Graduated` менше 1%, тому просто видалимо ці порожні значення. По колонці `Ever_Married`, `Profession`, `Work_Experience`, `Family_Size` здійснимо імпутацію для кожної з змінних за окремими логіками:\n",
    "- Ever_Married: для **null** значень заповнимо їх 0, так як таких значень менше 2%, це не сильно повпливає на результат вибірки і це інтуїтивно ближче до правди\n",
    "- Profession: таких записів 124, присвоїмо їх до мажорного класу Artist\n",
    "- Work_Experience: записів 829, припускаємо, що **null** значення описують таких, що не мають досвіду, тобто їхній досвід складає 0, заповнимо null 0\n",
    "- Family_Size: нул записів 335, заповнимо їх значенням 1, так як мінімальна можлива кількість членів родини - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Var_1'].isnull()].index.values, inplace=True)\n",
    "df.drop(df[df['Graduated'].isnull()].index.values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ever_Married'].fillna(0, inplace=True)\n",
    "df['Profession'].fillna('Artist', inplace=True)\n",
    "df['Work_Experience'].fillna(0, inplace=True)\n",
    "df['Family_Size'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "Gender             0\n",
       "Ever_Married       0\n",
       "Age                0\n",
       "Graduated          0\n",
       "Profession         0\n",
       "Work_Experience    0\n",
       "Spending_Score     0\n",
       "Family_Size        0\n",
       "Var_1              0\n",
       "Segmentation       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for Gender column ['Male' 'Female']\n",
      "\n",
      "Unique values for Ever_Married column ['No' 'Yes' 0]\n",
      "\n",
      "Unique values for Graduated column ['No' 'Yes']\n",
      "\n",
      "Unique values for Profession column ['Healthcare' 'Engineer' 'Lawyer' 'Entertainment' 'Artist' 'Executive'\n",
      " 'Doctor' 'Homemaker' 'Marketing']\n",
      "\n",
      "Unique values for Spending_Score column ['Low' 'Average' 'High']\n",
      "\n",
      "Unique values for Var_1 column ['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' 'Cat_5']\n",
      "\n",
      "Unique values for Segmentation column ['D' 'A' 'B' 'C']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.select_dtypes('object').columns:\n",
    "    print(f\"Unique values for {column} column {df[column].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "gender_map = {\"Male\": 0, \"Female\": 1}\n",
    "ever_marrier_map = {\"No\": 0, \"Yes\": 1}\n",
    "graduated_map = {\"No\": 0, \"Yes\": 1}\n",
    "segmentation_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "df['Gender'] = df['Gender'].replace(gender_map)\n",
    "df['Ever_Married'] = df['Ever_Married'].replace(ever_marrier_map)\n",
    "df['Graduated'] = df['Graduated'].replace(graduated_map)\n",
    "df['Segmentation'] = df['Segmentation'].replace(segmentation_map)\n",
    "\n",
    "spending_core_encoder = OrdinalEncoder(categories=[['Low', 'Average', 'High']])\n",
    "spending_core_encoder.fit(df[['Spending_Score']])\n",
    "df['Spending_Score'] = spending_core_encoder.transform(df[['Spending_Score']])\n",
    "\n",
    "\n",
    "categorical_columns = ['Profession', 'Var_1']\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "one_hot_encoder.fit(df[categorical_columns])\n",
    "encoded_categorical_columns = list(one_hot_encoder.get_feature_names_out())\n",
    "df[encoded_categorical_columns] = one_hot_encoder.transform(df[categorical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=categorical_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, df.columns != 'Segmentation']\n",
    "y = df['Segmentation']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhJzCBA7P0f8"
   },
   "source": [
    "**Завдання 2. Важливо уважно прочитати все формулювання цього завдання до кінця!**\n",
    "\n",
    "Застосуйте методи ресемплингу даних SMOTE та SMOTE-Tomek з бібліотеки imbalanced-learn до тренувальної вибірки. В результаті у Вас має вийти 2 тренувальних набори: з апсемплингом зі SMOTE, та з ресамплингом з SMOTE-Tomek.\n",
    "\n",
    "Увага! В нашому наборі даних є як категоріальні дані, так і звичайні числові. Базовий SMOTE не буде правильно працювати з категоріальними даними, але є його модифікація, яка буде. Тому в цього завдання є 2 виконання\n",
    "\n",
    "  1. Застосувати SMOTE базовий лише на НЕкатегоріальних ознаках.\n",
    "\n",
    "  2. Переглянути інформацію про метод [SMOTENC](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) і використати цей метод в цій задачі. За цей спосіб буде +3 бали за це завдання і він рекомендований для виконання.\n",
    "\n",
    "  **Підказка**: аби скористатись SMOTENC треба створити змінну, яка містить індекси ознак, які є категоріальними (їх номер серед колонок) і передати при ініціації екземпляра класу `SMOTENC(..., categorical_features=cat_feature_indeces)`.\n",
    "  \n",
    "  Ви також можете розглянути варіант використання варіації SMOTE, який працює ЛИШЕ з категоріальними ознаками [SMOTEN](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTEN.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "6NFUkQ_15HNX"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res_smote, y_train_res_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_res_smote_tomek, y_train_res_smote_tomek = smote_tomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset:  (6331, 24)\n",
      "Resampled train dataset with SMOTE:  (7116, 24)\n",
      "Resampled train dataset with SMOTETomek:  (5216, 24)\n"
     ]
    }
   ],
   "source": [
    "print('Original train dataset: ', X_train.shape)\n",
    "print('Resampled train dataset with SMOTE: ', X_train_res_smote.shape)\n",
    "print('Resampled train dataset with SMOTETomek: ', X_train_res_smote_tomek.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "smotenc = SMOTENC(categorical_features=[1, 2, 4, 6])\n",
    "X_train_res_smotenc, y_train_res_smotenc = smotenc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled train dataset with SMOTENC:  (7116, 24)\n",
      "\n",
      "Original y values: Segmentation\n",
      "2    1779\n",
      "0    1779\n",
      "3    1779\n",
      "1    1779\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled y values with SMOTENC: Segmentation\n",
      "3    1779\n",
      "2    1547\n",
      "0    1543\n",
      "1    1462\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Resampled train dataset with SMOTENC: ', X_train_res_smotenc.shape)\n",
    "print('\\nOriginal y values:', y_train_res_smotenc.value_counts())\n",
    "print('\\nResampled y values with SMOTENC:', y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja4w_GgmT4D0"
   },
   "source": [
    "**Завдання 3**.\n",
    "  1. Навчіть модель логістичної регресії з використанням стратегії One-vs-Rest з логістичною регресією на оригінальних даних, збалансованих з SMOTE, збалансованих з Smote-Tomek.  \n",
    "  2. Виміряйте якість кожної з натренованих моделей використовуючи `sklearn.metrics.classification_report`.\n",
    "  3. Напишіть, яку метрику ви обрали для порівняння моделей.\n",
    "  4. Яка модель найкраща?\n",
    "  5. Якщо немає суттєвої різниці між моделями - напишіть свою гіпотезу, чому?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "nxWVeRan5JBh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       386\n",
      "           1       0.00      0.00      0.00       365\n",
      "           2       0.00      0.00      0.00       387\n",
      "           3       0.28      1.00      0.44       445\n",
      "\n",
      "    accuracy                           0.28      1583\n",
      "   macro avg       0.07      0.25      0.11      1583\n",
      "weighted avg       0.08      0.28      0.12      1583\n",
      "\n",
      "Classification report for SMOTE resampled data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       386\n",
      "           1       0.23      1.00      0.37       365\n",
      "           2       0.00      0.00      0.00       387\n",
      "           3       0.00      0.00      0.00       445\n",
      "\n",
      "    accuracy                           0.23      1583\n",
      "   macro avg       0.06      0.25      0.09      1583\n",
      "weighted avg       0.05      0.23      0.09      1583\n",
      "\n",
      "Classification report for SMOTETomek resampled data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       386\n",
      "           1       0.00      0.00      0.00       365\n",
      "           2       0.33      0.67      0.44       387\n",
      "           3       0.44      0.79      0.57       445\n",
      "\n",
      "    accuracy                           0.39      1583\n",
      "   macro avg       0.19      0.37      0.25      1583\n",
      "weighted avg       0.20      0.39      0.27      1583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# One-vs-Rest\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "ovr_model = OneVsRestClassifier(log_reg)\n",
    "ovr_model.fit(X_train, y_train)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу на оригінальних даних\n",
    "print(\"Classification report for original data\")\n",
    "print(classification_report(y_test, ovr_predictions))\n",
    "\n",
    "ovr_model = OneVsRestClassifier(log_reg)\n",
    "ovr_model.fit(X_train_res_smote, y_train_res_smote)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу з resample SMOTE\n",
    "print(\"Classification report for SMOTE resampled data\")\n",
    "print(classification_report(y_test, ovr_predictions))\n",
    "\n",
    "ovr_model = OneVsRestClassifier(log_reg)\n",
    "ovr_model.fit(X_train_res_smote_tomek, y_train_res_smote_tomek)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу з resample SMOTE\n",
    "print(\"Classification report for SMOTETomek resampled data\")\n",
    "print(classification_report(y_test, ovr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.25      0.31       386\n",
      "           1       0.21      0.02      0.04       365\n",
      "           2       0.46      0.58      0.51       387\n",
      "           3       0.44      0.79      0.56       445\n",
      "\n",
      "    accuracy                           0.43      1583\n",
      "   macro avg       0.37      0.41      0.36      1583\n",
      "weighted avg       0.38      0.43      0.37      1583\n",
      "\n",
      "Classification report for SMOTE resampled data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.47       386\n",
      "           1       0.40      0.28      0.33       365\n",
      "           2       0.48      0.61      0.54       387\n",
      "           3       0.68      0.67      0.68       445\n",
      "\n",
      "    accuracy                           0.52      1583\n",
      "   macro avg       0.51      0.51      0.50      1583\n",
      "weighted avg       0.51      0.52      0.51      1583\n",
      "\n",
      "Classification report for SMOTETomek resampled data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.19      0.25       386\n",
      "           1       0.24      0.05      0.08       365\n",
      "           2       0.38      0.73      0.50       387\n",
      "           3       0.57      0.72      0.64       445\n",
      "\n",
      "    accuracy                           0.44      1583\n",
      "   macro avg       0.39      0.42      0.37      1583\n",
      "weighted avg       0.40      0.44      0.38      1583\n",
      "\n",
      "Classification report for SMOTENC resampled data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45       386\n",
      "           1       0.40      0.29      0.34       365\n",
      "           2       0.49      0.60      0.54       387\n",
      "           3       0.68      0.68      0.68       445\n",
      "\n",
      "    accuracy                           0.52      1583\n",
      "   macro avg       0.50      0.51      0.50      1583\n",
      "weighted avg       0.51      0.52      0.51      1583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One-vs-One\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "ovr_model = OneVsOneClassifier(log_reg)\n",
    "ovr_model.fit(X_train, y_train)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу на оригінальних даних\n",
    "print(\"Classification report for original data\")\n",
    "print(classification_report(y_test, ovr_predictions))\n",
    "\n",
    "ovr_model = OneVsOneClassifier(log_reg)\n",
    "ovr_model.fit(X_train_res_smote, y_train_res_smote)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу з resample SMOTE\n",
    "print(\"Classification report for SMOTE resampled data\")\n",
    "print(classification_report(y_test, ovr_predictions))\n",
    "\n",
    "ovr_model = OneVsOneClassifier(log_reg)\n",
    "ovr_model.fit(X_train_res_smote_tomek, y_train_res_smote_tomek)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу з resample SMOTE\n",
    "print(\"Classification report for SMOTETomek resampled data\")\n",
    "print(classification_report(y_test, ovr_predictions))\n",
    "\n",
    "ovr_model = OneVsOneClassifier(log_reg)\n",
    "ovr_model.fit(X_train_res_smotenc, y_train_res_smotenc)\n",
    "ovr_predictions = ovr_model.predict(X_test)\n",
    "\n",
    "# Обчислимо метрики precision та recall для кожного класу з resample SMOTE\n",
    "print(\"Classification report for SMOTENC resampled data\")\n",
    "print(classification_report(y_test, ovr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегія `One-vs-Rest` показала гірші результати, аніж стратегія `One-vs-One` у поєднанні з логістичною регресією. Щодо ресемплінгу, SMOTENC та SMOTE показали найкращі результати. Залежно від поставленої задачі, я обрав метрику precision, оскільки неправильне передбачення не має явної критичної точки некоректного прогнозу. Якби це була задача виявлення хвороби - я обрав би recall, так як нам важливо не помилитись у визначення діагнозу. Так як це задача передбачення для маркетингу, ми можемо дозволити помилитись, проте в даному випадку важливіже \"потрапити в ціль\" та обрати коректних клієнтів. Отже, стратегія `One-vs-One` у поєднанні з `SMOTENC` дала найкращі, проте далеко не ідеальні результати. Macro avg - 0.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
